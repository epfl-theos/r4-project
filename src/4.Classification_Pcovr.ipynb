{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d4f8a0",
   "metadata": {},
   "source": [
    "These produce a final .json file that can be used as an input in chemiscope to produce the final figures of the manuscript. \n",
    "The file can be already found in the downloaded folder.\n",
    "However, if you want to run the notebook yourself, a new chemiscope file will be generated, along with new pcovr figures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./modules.ipynb\n",
    "%run ./data.ipynb\n",
    "\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "my_c = colors.ListedColormap([\"mediumblue\", \"red\"])\n",
    "c = [\"mediumblue\", \"red\"]\n",
    "sns.set_palette(sns.color_palette(c))\n",
    "\n",
    "n_PC = 5  # number of principal components\n",
    "mixing = 0.5  # beta parameter for pcvor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(\"../r4data\").exists():\n",
    "    npzfile = np.load(DATA_MP.soap_red, allow_pickle=True)\n",
    "    my_frames = npzfile[\"my_frames\"]\n",
    "    idx = npzfile[\"idx\"]\n",
    "    magic = npzfile[\"magic\"]\n",
    "    X_raw = npzfile[\"X_raw\"]\n",
    "    coeff = npzfile[\"coeff\"]\n",
    "    magic = [int(i) for i in magic]\n",
    "    magic = np.array(magic).reshape(-1, 1)\n",
    "    y_magic = np.copy(magic.reshape(-1, 1).ravel())\n",
    "\n",
    "    comp_classif(X_raw, y_magic)  # prints out test set accuracy on all models\n",
    "\n",
    "    X = np.copy(X_raw)\n",
    "    y_magic = np.copy(magic.reshape(-1, 1))\n",
    "\n",
    "    i_train, i_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.arange(X.shape[0]), X, y_magic, train_size=0.8\n",
    "    )\n",
    "    x_scaler = StandardFlexibleScaler(column_wise=False).fit(X)\n",
    "    # Center total dataset\n",
    "    X = x_scaler.transform(X)\n",
    "    # Center training data\n",
    "    X_train = x_scaler.transform(X_train)\n",
    "    # Center training data\n",
    "    X_test = x_scaler.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf.predict(X_test)\n",
    "    print(\"Accuracy on test set:\" + str(clf.score(X_test, y_test)))\n",
    "    p_random_for = clf.predict_proba(X)\n",
    "\n",
    "    y_tot = p_random_for[:, 1].reshape(-1, 1)\n",
    "    i_train, i_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.arange(X.shape[0]), X, y_tot, train_size=0.8\n",
    "    )\n",
    "\n",
    "    x_scaler = StandardFlexibleScaler(column_wise=False).fit(X)\n",
    "    y_scaler = StandardFlexibleScaler(column_wise=True).fit(y_tot)\n",
    "\n",
    "    # Center total dataset\n",
    "    X = x_scaler.transform(X)\n",
    "    Y = y_scaler.transform(y_tot)\n",
    "\n",
    "    # Center training data\n",
    "    X_train = x_scaler.transform(X_train)\n",
    "    y_train = y_scaler.transform(y_train)\n",
    "\n",
    "    # Center training data\n",
    "    X_test = x_scaler.transform(X_test)\n",
    "    y_test = y_scaler.transform(y_test)\n",
    "\n",
    "    pcovr = PCovR(mixing=mixing, n_components=n_PC)\n",
    "    pcovr.fit(X, Y)\n",
    "    T = pcovr.transform(X)\n",
    "    yp = pcovr.predict(X)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    ax1.scatter(T[:, 0], T[:, 1], s=50, alpha=0.3, c=p_random_for[:, 1], cmap=\"bwr\")\n",
    "    ax1.set_xlabel(r\"$PCov_1$\")\n",
    "    ax1.set_ylabel(r\"$PCov_2$\")\n",
    "\n",
    "    ax2.scatter(Y, yp, s=50, alpha=0.5, c=np.abs(Y - yp), cmap=\"bone_r\")\n",
    "    ax2.plot(ax2.get_xlim(), ax2.get_xlim(), \"r--\")\n",
    "    ax2.set_xlabel(r\"y\")\n",
    "    ax2.set_ylabel(r\"predicted y\")\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    # Exploring correlation with other features\n",
    "    if DATA_MP.geo.exists():\n",
    "\n",
    "        upper_bound = (\n",
    "            0.4  # number above which the correlation is considered HIGH (maximum is 1)\n",
    "        )\n",
    "        lower_bound = (\n",
    "            0  # number below which the correlation is considered LOW (minimumis -1)\n",
    "        )\n",
    "\n",
    "        col = range(0, len(X_raw))\n",
    "        df = pd.DataFrame(data=X_raw, index=col)\n",
    "        df[r\"PC$_{1}$\"] = T[:, 0]\n",
    "        corr = df.corrwith(df[r\"PC$_{1}$\"])\n",
    "\n",
    "        low_corr_soap = []\n",
    "        high_corr_soap = []\n",
    "        for i in range(len(corr) - 1):\n",
    "            if corr[i] < -lower_bound:\n",
    "                low_corr_soap.append(i)\n",
    "            if corr[i] > upper_bound:\n",
    "                high_corr_soap.append(i)\n",
    "            high_corr = [coeff[i] for i in high_corr_soap]\n",
    "            low_corr = [coeff[i] for i in low_corr_soap]\n",
    "        npzfile = np.load(DATA_MP.geo, allow_pickle=True)\n",
    "        magic = npzfile[\"magic\"]\n",
    "        natoms = npzfile[\"natoms\"]\n",
    "        std_ratio = npzfile[\"std_ratio\"]\n",
    "        n_species = npzfile[\"n_species\"]\n",
    "        alpha = npzfile[\"alpha\"]\n",
    "        x = npzfile[\"x\"]\n",
    "        cn = npzfile[\"cn\"]\n",
    "        packing = npzfile[\"packing\"]\n",
    "        fcc = npzfile[\"fcc\"]\n",
    "        hcp = npzfile[\"hcp\"]\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=(12, 8))\n",
    "        dict_corr = {\n",
    "            r\"$\\alpha$\": alpha,\n",
    "            r\"$x$\": x,\n",
    "            r\"$\\sigma_{radii}$\": std_ratio,\n",
    "            r\"$CN_{avg}$\": cn,\n",
    "            r\"$PF$\": packing,\n",
    "            r\"P$_{classif}$\": p_random_for[:, 1],\n",
    "            r\"$N_{species}$\": n_species,\n",
    "            r\"PCov$_{1}$\": T[:, 0],\n",
    "            r\"PCov$_{4}$\": T[:, 3],\n",
    "        }\n",
    "        df_corr = pd.DataFrame(dict_corr)\n",
    "        sns.heatmap(df_corr.corr(), vmin=-1, vmax=1, annot=True)\n",
    "        plt.show()\n",
    "\n",
    "    if not DATA_MP.chem.exists():\n",
    "        data = write_input(\n",
    "            path=\"../r4data/MP/chem.npz\",\n",
    "            meta={\"name\": \"PCovR\"},\n",
    "            frames=my_frames,\n",
    "            properties={\n",
    "                **{\n",
    "                    f\"PCoV_{i+1}\": {\"target\": \"structure\", \"values\": T[:, i]}\n",
    "                    for i in range(n_PC)\n",
    "                },\n",
    "                \"magic\": {\n",
    "                    \"target\": \"structure\",\n",
    "                    \"values\": magic,\n",
    "                },\n",
    "                \"magic probability\": {\n",
    "                    \"target\": \"structure\",\n",
    "                    \"values\": p_random_for[:, 1],\n",
    "                },\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4626d",
   "metadata": {},
   "source": [
    "3DCD data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(\"../r4data\").exists():\n",
    "    npzfile = np.load(DATA_3DCD.soap_red, allow_pickle=True)\n",
    "    my_frames = npzfile[\"my_frames\"]\n",
    "    idx = npzfile[\"idx\"]\n",
    "    magic = npzfile[\"magic\"]\n",
    "    X_raw = npzfile[\"X_raw\"]\n",
    "    coeff = npzfile[\"coeff\"]\n",
    "    magic = [int(i) for i in magic]\n",
    "    magic = np.array(magic).reshape(-1, 1)\n",
    "    y_magic = np.copy(magic.reshape(-1, 1).ravel())\n",
    "\n",
    "    comp_classif(X_raw, y_magic)  # prints out test set accuracy on all models\n",
    "\n",
    "    X = np.copy(X_raw)\n",
    "    y_magic = np.copy(magic.reshape(-1, 1))\n",
    "\n",
    "    i_train, i_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.arange(X.shape[0]), X, y_magic, train_size=0.8\n",
    "    )\n",
    "    x_scaler = StandardFlexibleScaler(column_wise=False).fit(X)\n",
    "    # Center total dataset\n",
    "    X = x_scaler.transform(X)\n",
    "    # Center training data\n",
    "    X_train = x_scaler.transform(X_train)\n",
    "    # Center training data\n",
    "    X_test = x_scaler.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf.predict(X_test)\n",
    "    print(\"Accuracy on test set:\" + str(clf.score(X_test, y_test)))\n",
    "    p_random_for = clf.predict_proba(X)\n",
    "\n",
    "    y_tot = p_random_for[:, 1].reshape(-1, 1)\n",
    "    i_train, i_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.arange(X.shape[0]), X, y_tot, train_size=0.8\n",
    "    )\n",
    "\n",
    "    x_scaler = StandardFlexibleScaler(column_wise=False).fit(X)\n",
    "    y_scaler = StandardFlexibleScaler(column_wise=True).fit(y_tot)\n",
    "\n",
    "    # Center total dataset\n",
    "    X = x_scaler.transform(X)\n",
    "    Y = y_scaler.transform(y_tot)\n",
    "\n",
    "    # Center training data\n",
    "    X_train = x_scaler.transform(X_train)\n",
    "    y_train = y_scaler.transform(y_train)\n",
    "\n",
    "    # Center training data\n",
    "    X_test = x_scaler.transform(X_test)\n",
    "    y_test = y_scaler.transform(y_test)\n",
    "\n",
    "    pcovr = PCovR(mixing=mixing, n_components=n_PC)\n",
    "    pcovr.fit(X, Y)\n",
    "    T = pcovr.transform(X)\n",
    "    yp = pcovr.predict(X)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    ax1.scatter(T[:, 0], T[:, 1], s=50, alpha=0.3, c=p_random_for[:, 1], cmap=\"bwr\")\n",
    "    ax1.set_xlabel(r\"$PCov_1$\")\n",
    "    ax1.set_ylabel(r\"$PCov_2$\")\n",
    "\n",
    "    ax2.scatter(Y, yp, s=50, alpha=0.5, c=np.abs(Y - yp), cmap=\"bone_r\")\n",
    "    ax2.plot(ax2.get_xlim(), ax2.get_xlim(), \"r--\")\n",
    "    ax2.set_xlabel(r\"y\")\n",
    "    ax2.set_ylabel(r\"predicted y\")\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    #     #Exploring correlation with other features\n",
    "    #     if DATA_3DCD.geo.exists():\n",
    "\n",
    "    #         upper_bound=0.4 #number above which the correlation is considered HIGH (maximum is 1)\n",
    "    #         lower_bound=0 #number below which the correlation is considered LOW (minimumis -1)\n",
    "\n",
    "    #         col=range(0, len(X_raw))\n",
    "    #         df = pd.DataFrame(data=X_raw, index=col)\n",
    "    #         df[r'PC$_{1}$']=T[:,0]\n",
    "    #         corr=df.corrwith(df[r'PC$_{1}$'])\n",
    "    #         print(min(corr), max(corr), len(corr))\n",
    "    #         print(corr)\n",
    "    #         low_corr_soap=[]\n",
    "    #         high_corr_soap=[]\n",
    "    #         for i in range(len(corr)-1):\n",
    "    #             if corr[i] <- lower_bound:\n",
    "    #                 low_corr_soap.append(i)\n",
    "    #             if corr[i] > upper_bound:\n",
    "    #                 high_corr_soap.append(i)\n",
    "    #             high_corr=[coeff[i] for i in high_corr_soap]\n",
    "    #             low_corr=[coeff[i] for i in low_corr_soap]\n",
    "    #         npzfile = np.load(DATA_MP.geo, allow_pickle=True)\n",
    "    #         magic=npzfile['magic']\n",
    "    #         natoms=npzfile['natoms']\n",
    "    #         std_ratio=npzfile['std_ratio']\n",
    "    #         n_species=npzfile['n_species']\n",
    "    #         alpha=npzfile['alpha']\n",
    "    #         x=npzfile['x']\n",
    "    #         cn=npzfile['cn']\n",
    "    #         packing=npzfile['packing']\n",
    "    #         fcc=npzfile['fcc']\n",
    "    #         hcp=npzfile['hcp']\n",
    "\n",
    "    #         fig, axes = plt.subplots(figsize=(12,8))\n",
    "    #         dict_corr={r'$\\alpha$':alpha,r'$x$':x, r'$\\sigma_{radii}$':std_ratio,\n",
    "    #             r'$CN_{avg}$':cn, r'$PF$':packing,r'P$_{classif}$':p_random_for[:,1],\n",
    "    #               r'$N_{species}$': n_species,r'PCov$_{1}$': T[:,0], r'PCov$_{4}$': T[:,3]}\n",
    "    #         df_corr= pd.DataFrame(dict_corr)\n",
    "    #         sns.heatmap(df_corr.corr(), vmin=-1, vmax=1, annot=True)\n",
    "    #         plt.show()\n",
    "\n",
    "    if not DATA_3DCD.chem_red.exists():\n",
    "        data = write_input(\n",
    "            path=\"../r4data/3DCD/chem_red.npz\",\n",
    "            meta={\"name\": \"3DCD PCovR\"},\n",
    "            frames=my_frames,\n",
    "            properties={\n",
    "                **{\n",
    "                    f\"PCoV_{i+1}\": {\"target\": \"structure\", \"values\": T[:, i]}\n",
    "                    for i in range(n_PC)\n",
    "                },\n",
    "                \"magic\": {\n",
    "                    \"target\": \"structure\",\n",
    "                    \"values\": magic,\n",
    "                },\n",
    "                \"magic probability\": {\n",
    "                    \"target\": \"structure\",\n",
    "                    \"values\": p_random_for[:, 1],\n",
    "                },\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91262e9b",
   "metadata": {},
   "source": [
    "MP data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515043dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(\"../r4data\").exists():\n",
    "    npzfile = np.load(DATA_MP.soap_red, allow_pickle=True)\n",
    "    my_frames = npzfile[\"my_frames\"]\n",
    "    idx = npzfile[\"idx\"]\n",
    "    magic = npzfile[\"magic\"]\n",
    "    X_raw = npzfile[\"X_raw\"]\n",
    "    coeff = npzfile[\"coeff\"]\n",
    "    magic = [int(i) for i in magic]\n",
    "    magic = np.array(magic).reshape(-1, 1)\n",
    "    y_magic = np.copy(magic.reshape(-1, 1).ravel())\n",
    "\n",
    "    comp_classif(X_raw, y_magic)  # prints out test set accuracy on all models\n",
    "\n",
    "    X = np.copy(X_raw)\n",
    "    y_magic = np.copy(magic.reshape(-1, 1))\n",
    "\n",
    "    i_train, i_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.arange(X.shape[0]), X, y_magic, train_size=0.8\n",
    "    )\n",
    "    x_scaler = StandardFlexibleScaler(column_wise=False).fit(X)\n",
    "    # Center total dataset\n",
    "    X = x_scaler.transform(X)\n",
    "    # Center training data\n",
    "    X_train = x_scaler.transform(X_train)\n",
    "    # Center training data\n",
    "    X_test = x_scaler.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf.predict(X_test)\n",
    "    print(\"Accuracy on test set:\" + str(clf.score(X_test, y_test)))\n",
    "    p_random_for = clf.predict_proba(X)\n",
    "\n",
    "    y_tot = p_random_for[:, 1].reshape(-1, 1)\n",
    "    i_train, i_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.arange(X.shape[0]), X, y_tot, train_size=0.8\n",
    "    )\n",
    "\n",
    "    x_scaler = StandardFlexibleScaler(column_wise=False).fit(X)\n",
    "    y_scaler = StandardFlexibleScaler(column_wise=True).fit(y_tot)\n",
    "\n",
    "    # Center total dataset\n",
    "    X = x_scaler.transform(X)\n",
    "    Y = y_scaler.transform(y_tot)\n",
    "\n",
    "    # Center training data\n",
    "    X_train = x_scaler.transform(X_train)\n",
    "    y_train = y_scaler.transform(y_train)\n",
    "\n",
    "    # Center training data\n",
    "    X_test = x_scaler.transform(X_test)\n",
    "    y_test = y_scaler.transform(y_test)\n",
    "\n",
    "    pcovr = PCovR(mixing=mixing, n_components=n_PC)\n",
    "    pcovr.fit(X, Y)\n",
    "    T = pcovr.transform(X)\n",
    "    yp = pcovr.predict(X)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    ax1.scatter(T[:, 0], T[:, 1], s=50, alpha=0.3, c=p_random_for[:, 1], cmap=\"bwr\")\n",
    "    ax1.set_xlabel(r\"$PCov_1$\")\n",
    "    ax1.set_ylabel(r\"$PCov_2$\")\n",
    "\n",
    "    ax2.scatter(Y, yp, s=50, alpha=0.5, c=np.abs(Y - yp), cmap=\"bone_r\")\n",
    "    ax2.plot(ax2.get_xlim(), ax2.get_xlim(), \"r--\")\n",
    "    ax2.set_xlabel(r\"y\")\n",
    "    ax2.set_ylabel(r\"predicted y\")\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    #     #Exploring correlation with other features\n",
    "    #     if DATA_MP.geo.exists():\n",
    "\n",
    "    #         upper_bound=0.4 #number above which the correlation is considered HIGH (maximum is 1)\n",
    "    #         lower_bound=0 #number below which the correlation is considered LOW (minimumis -1)\n",
    "\n",
    "    #         col=range(0, len(X_raw))\n",
    "    #         df = pd.DataFrame(data=X_raw, index=col)\n",
    "    #         df[r'PC$_{1}$']=T[:,0]\n",
    "    #         corr=df.corrwith(df[r'PC$_{1}$'])\n",
    "    #         print(min(corr), max(corr), len(corr))\n",
    "    #         print(corr)\n",
    "    #         low_corr_soap=[]\n",
    "    #         high_corr_soap=[]\n",
    "    #         for i in range(len(corr)-1):\n",
    "    #             if corr[i] <- lower_bound:\n",
    "    #                 low_corr_soap.append(i)\n",
    "    #             if corr[i] > upper_bound:\n",
    "    #                 high_corr_soap.append(i)\n",
    "    #             high_corr=[coeff[i] for i in high_corr_soap]\n",
    "    #             low_corr=[coeff[i] for i in low_corr_soap]\n",
    "    #         npzfile = np.load(DATA_MP.geo, allow_pickle=True)\n",
    "    #         magic=npzfile['magic']\n",
    "    #         natoms=npzfile['natoms']\n",
    "    #         std_ratio=npzfile['std_ratio']\n",
    "    #         n_species=npzfile['n_species']\n",
    "    #         alpha=npzfile['alpha']\n",
    "    #         x=npzfile['x']\n",
    "    #         cn=npzfile['cn']\n",
    "    #         packing=npzfile['packing']\n",
    "    #         fcc=npzfile['fcc']\n",
    "    #         hcp=npzfile['hcp']\n",
    "\n",
    "    #         fig, axes = plt.subplots(figsize=(12,8))\n",
    "    #         dict_corr={r'$\\alpha$':alpha,r'$x$':x, r'$\\sigma_{radii}$':std_ratio,\n",
    "    #             r'$CN_{avg}$':cn, r'$PF$':packing,r'P$_{classif}$':p_random_for[:,1],\n",
    "    #               r'$N_{species}$': n_species,r'PCov$_{1}$': T[:,0], r'PCov$_{4}$': T[:,3]}\n",
    "    #         df_corr= pd.DataFrame(dict_corr)\n",
    "    #         sns.heatmap(df_corr.corr(), vmin=-1, vmax=1, annot=True)\n",
    "    #         plt.show()\n",
    "\n",
    "    if not DATA_MP.chem_red.exists():\n",
    "        data = write_input(\n",
    "            path=\"../r4data/MP/chem_red.npz\",\n",
    "            meta={\"name\": \"MP PCovR\"},\n",
    "            frames=my_frames,\n",
    "            properties={\n",
    "                **{\n",
    "                    f\"PCoV_{i+1}\": {\"target\": \"structure\", \"values\": T[:, i]}\n",
    "                    for i in range(n_PC)\n",
    "                },\n",
    "                \"magic\": {\n",
    "                    \"target\": \"structure\",\n",
    "                    \"values\": magic,\n",
    "                },\n",
    "                \"magic probability\": {\n",
    "                    \"target\": \"structure\",\n",
    "                    \"values\": p_random_for[:, 1],\n",
    "                },\n",
    "            },\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
