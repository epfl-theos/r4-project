{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `Group` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `AutoGroup` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `ImportGroup` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `UpfFamily` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n"
     ]
    }
   ],
   "source": [
    "%run ./modules.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to input .xyz data and output .npz SOAP vector files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"With example MP data\"\"\"\n",
    "\n",
    "path_to_input='../example_data/example_data_MP.xyz'\n",
    "path_to_output='../example_data/example_SOAP_MP.npz'\n",
    "\n",
    "\"\"\"For a complete analysis, uncomment the following lines:\"\"\"\n",
    "# path_to_input='../r4data/3dcd.xyz'\n",
    "# path_to_output='../r4data/3DCD_SOAP_tot.npz'\n",
    "# # OR\n",
    "# path_to_input='../r4data/MP.xyz'\n",
    "# path_to_output='../r4data/MP_SOAP_tot.npz'\n",
    "\n",
    "frames_relax_tot=ase.io.read(path_to_input, index=':')\n",
    "len(frames_relax_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_FPS=2000   # number of most fiverse features selected \n",
    "n_frames=len(frames_relax_tot)    # number of structures analysed, the whole dataset will take some time\n",
    "n_PC=5    # number of principal components to include in the analysis (min=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic=np.zeros((len(frames_relax_tot)))\n",
    "for frame, i in zip(frames_relax_tot, range(len(frames_relax_tot))):\n",
    "    frame.wrap(eps=1e-12)\n",
    "    if len(frame)%4==0:\n",
    "        magic[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = list(set([int(n) for frame in frames_relax_tot for n in frame.numbers]))\n",
    "\n",
    "hypers = dict(\n",
    "    soap_type=\"PowerSpectrum\",\n",
    "    interaction_cutoff=3.5,\n",
    "    max_radial=4,\n",
    "    max_angular=4,\n",
    "    gaussian_sigma_type=\"Constant\",\n",
    "    gaussian_sigma_constant=0.5,\n",
    "    cutoff_smooth_width=0.5,\n",
    "    global_species=species,\n",
    "    expansion_by_species_method=\"user defined\",\n",
    "    normalize=False,\n",
    ")\n",
    "fps_soap = SOAP(\n",
    "    **hypers,\n",
    ")\n",
    "idx_for_fps = np.random.randint(0, len(frames_relax_tot), n_FPS) \n",
    "frames_for_fps = [frames_relax_tot[i] for i in idx_for_fps]\n",
    "X_temp = np.array(\n",
    "    [\n",
    "        np.mean(fps_soap.transform([frame]).get_features(fps_soap), axis=0)\n",
    "        for frame in frames_for_fps\n",
    "    ]\n",
    ")\n",
    "\n",
    "THRESH = 1e-12\n",
    "high_var_features = np.where(np.var(X_temp - X_temp.mean(axis=0), axis=0) > THRESH)[0]\n",
    "X_temp = X_temp[:, high_var_features]\n",
    "\n",
    "X_raw = StandardFlexibleScaler(column_wise=False).fit_transform(X_temp)\n",
    "del X_temp # save on memory\n",
    "fps = FPS(n_FPS).fit(X_raw)\n",
    "del X_raw \n",
    "u_species = np.unique(species)\n",
    "sp_pairs = fps_soap.get_keys(u_species)\n",
    "\n",
    "coefficient_subselection = np.zeros((n_FPS, 5))\n",
    "index_mapping = get_power_spectrum_index_mapping(\n",
    "    sp_pairs, n_max=hypers[\"max_radial\"], l_max=hypers[\"max_angular\"] + 1\n",
    ")\n",
    "for fi, i in enumerate(high_var_features[fps.selected_idx_]):\n",
    "    coefficient_subselection[fi] = [\n",
    "        index_mapping[i][k] for k in [\"a\", \"b\", \"n1\", \"n2\", \"l\"]\n",
    "    ]\n",
    "coefficient_subselection_dict = {\n",
    "    \"a\": coefficient_subselection[:, 0].tolist(),\n",
    "    \"b\": coefficient_subselection[:, 1].tolist(),\n",
    "    \"n1\": coefficient_subselection[:, 2].tolist(),\n",
    "    \"n2\": coefficient_subselection[:, 3].tolist(),\n",
    "    \"l\": coefficient_subselection[:, 4].tolist(),\n",
    "}\n",
    "\n",
    "soap = SOAP(**hypers, coefficient_subselection=coefficient_subselection_dict)\n",
    "idx = np.random.randint(0, len(frames_relax_tot), n_frames) \n",
    "my_frames= [frames_relax_tot[i] for i in idx]\n",
    "\n",
    "magic=magic.reshape(-1, 1)[idx]\n",
    "               \n",
    "X_raw = np.zeros((len(my_frames), n_FPS))\n",
    "for fi, frame in enumerate(my_frames):\n",
    "    X_raw[fi] = np.mean(soap.transform([frame]).get_features(soap), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING THE NPZ SOAP VECTOR FILE IN YOUR REPO SO THAT YOU DON'T HAVE TO RUN THE ABOVE EVERY TIME (14 MB FOR FPS=2000, n_PC=5, n_frames=840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egazzarrini/miniconda3/envs/aiida/lib/python3.8/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "file=np.savez(path_to_output, idx=idx, my_frames=my_frames,\n",
    "            magic=magic ,X_raw=X_raw, coeff=coefficient_subselection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
