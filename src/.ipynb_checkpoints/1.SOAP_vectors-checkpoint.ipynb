{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10122cc8",
   "metadata": {},
   "source": [
    "This notebook is just a demonstration on how the SOAP vectors are obtained starting from the .xyz files. \n",
    "The soap.npz files were already generated and can be downloaded, so there is no real need to run this notebook. \n",
    "If you decide to run it anyways using production data, be prepared to wait for a while, depending on the power of your RAM. The output files will be called 'generated_soap*.npz'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0648d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `Group` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `AutoGroup` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `ImportGroup` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/aiida/orm/groups.py:61: UserWarning: no registered entry point for `UpfFamily` so its instances will not be storable.\n",
      "  warnings.warn(message)  # pylint: disable=no-member\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PRODUCTION DATA NOT PRESENT, USING EXAMPLE DATA FROM REDUCED MP DATA SET!!\n"
     ]
    }
   ],
   "source": [
    "%run ./modules.ipynb\n",
    "%run ./data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2722544a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 840)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_3dcd=ase.io.read(DATA_3DCD.structures, index=':')\n",
    "frames_mp=ase.io.read(DATA_MP.structures, index=':')\n",
    "len(frames_3dcd), len(frames_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6f7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=frames_3dcd\n",
    "n_FPS=2000   # number of most fiverse features selected \n",
    "n_frames=len(frames)    # number of structures analysed, the whole dataset will take some time\n",
    "n_PC=5    # number of principal components to include in the analysis (min=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b8ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "magic=np.zeros((len(frames)))\n",
    "for frame, i in zip(frames, range(len(frames))):\n",
    "    frame.wrap(eps=1e-12)\n",
    "    if len(frame)%4==0:\n",
    "        magic[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c16794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498f3c44f21c4ab4a40a468b590efc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "species = list(set([int(n) for frame in frames for n in frame.numbers]))\n",
    "\n",
    "hypers = dict(\n",
    "    soap_type=\"PowerSpectrum\",\n",
    "    interaction_cutoff=3.5,\n",
    "    max_radial=4,\n",
    "    max_angular=4,\n",
    "    gaussian_sigma_type=\"Constant\",\n",
    "    gaussian_sigma_constant=0.5,\n",
    "    cutoff_smooth_width=0.5,\n",
    "    global_species=species,\n",
    "    expansion_by_species_method=\"user defined\",\n",
    "    normalize=False,\n",
    ")\n",
    "fps_soap = SOAP(\n",
    "    **hypers,\n",
    ")\n",
    "idx_for_fps = np.random.randint(0, len(frames), n_FPS) \n",
    "frames_for_fps = [frames[i] for i in idx_for_fps]\n",
    "X_temp = np.array(\n",
    "    [\n",
    "        np.mean(fps_soap.transform([frame]).get_features(fps_soap), axis=0)\n",
    "        for frame in frames_for_fps\n",
    "    ]\n",
    ")\n",
    "\n",
    "THRESH = 1e-12\n",
    "high_var_features = np.where(np.var(X_temp - X_temp.mean(axis=0), axis=0) > THRESH)[0]\n",
    "X_temp = X_temp[:, high_var_features]\n",
    "\n",
    "X_raw = StandardFlexibleScaler(column_wise=False).fit_transform(X_temp)\n",
    "del X_temp # save on memory\n",
    "fps =FPS(n_to_select=n_FPS, progress_bar=True).fit(X_raw)\n",
    "del X_raw \n",
    "u_species = np.unique(species)\n",
    "sp_pairs = fps_soap.get_keys(u_species)\n",
    "\n",
    "coefficient_subselection = np.zeros((n_FPS, 5))\n",
    "index_mapping = get_power_spectrum_index_mapping(\n",
    "    sp_pairs, n_max=hypers[\"max_radial\"], l_max=hypers[\"max_angular\"] + 1\n",
    ")\n",
    "for fi, i in enumerate(high_var_features[fps.selected_idx_]):\n",
    "    coefficient_subselection[fi] = [\n",
    "        index_mapping[i][k] for k in [\"a\", \"b\", \"n1\", \"n2\", \"l\"]\n",
    "    ]\n",
    "coefficient_subselection_dict = {\n",
    "    \"a\": coefficient_subselection[:, 0].tolist(),\n",
    "    \"b\": coefficient_subselection[:, 1].tolist(),\n",
    "    \"n1\": coefficient_subselection[:, 2].tolist(),\n",
    "    \"n2\": coefficient_subselection[:, 3].tolist(),\n",
    "    \"l\": coefficient_subselection[:, 4].tolist(),\n",
    "}\n",
    "\n",
    "soap = SOAP(**hypers, coefficient_subselection=coefficient_subselection_dict)\n",
    "idx = np.random.randint(0, len(frames), n_frames) \n",
    "my_frames= [frames[i] for i in idx]\n",
    "\n",
    "magic=magic.reshape(-1, 1)[idx]\n",
    "               \n",
    "X_raw = np.zeros((len(my_frames), n_FPS))\n",
    "for fi, frame in enumerate(my_frames):\n",
    "    X_raw[fi] = np.mean(soap.transform([frame]).get_features(soap), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d497da99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8fdef",
   "metadata": {},
   "source": [
    "SAVING THE NPZ SOAP VECTOR FILE IN YOUR REPO SO THAT YOU DON'T HAVE TO RUN THE ABOVE EVERY TIME (14 MB FOR FPS=2000, n_PC=5, n_frames=840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_3DCD.soap.exists():\n",
    "    print('Saving the data if it doesnt already exist')\n",
    "    file=np.savez('../r4data/3DCD/soap.npz', idx=idx, my_frames=my_frames,\n",
    "            magic=magic ,X_raw=X_raw, coeff=coefficient_subselection)\n",
    "else:\n",
    "    print('Data already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbaad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_FPS=2000   # number of most fiverse features selected \n",
    "n_frames=len(frames_mp)    # number of structures analysed, the whole dataset will take some time\n",
    "n_PC=5    # number of principal components to include in the analysis (min=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a94fc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=frames_mp\n",
    "\n",
    "magic=np.zeros((len(frames)))\n",
    "for frame, i in zip(frames, range(len(frames))):\n",
    "    frame.wrap(eps=1e-12)\n",
    "    if len(frame)%4==0:\n",
    "        magic[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510928eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = list(set([int(n) for frame in frames for n in frame.numbers]))\n",
    "\n",
    "hypers = dict(\n",
    "    soap_type=\"PowerSpectrum\",\n",
    "    interaction_cutoff=3.5,\n",
    "    max_radial=4,\n",
    "    max_angular=4,\n",
    "    gaussian_sigma_type=\"Constant\",\n",
    "    gaussian_sigma_constant=0.5,\n",
    "    cutoff_smooth_width=0.5,\n",
    "    global_species=species,\n",
    "    expansion_by_species_method=\"user defined\",\n",
    "    normalize=False,\n",
    ")\n",
    "fps_soap = SOAP(\n",
    "    **hypers,\n",
    ")\n",
    "idx_for_fps = np.random.randint(0, len(frames), n_FPS) \n",
    "frames_for_fps = [frames[i] for i in idx_for_fps]\n",
    "X_temp = np.array(\n",
    "    [\n",
    "        np.mean(fps_soap.transform([frame]).get_features(fps_soap), axis=0)\n",
    "        for frame in frames_for_fps\n",
    "    ]\n",
    ")\n",
    "\n",
    "THRESH = 1e-12\n",
    "high_var_features = np.where(np.var(X_temp - X_temp.mean(axis=0), axis=0) > THRESH)[0]\n",
    "X_temp = X_temp[:, high_var_features]\n",
    "\n",
    "X_raw = StandardFlexibleScaler(column_wise=False).fit_transform(X_temp)\n",
    "del X_temp # save on memory\n",
    "fps =FPS(n_to_select=n_FPS, progress_bar=True).fit(X_raw)\n",
    "del X_raw \n",
    "u_species = np.unique(species)\n",
    "sp_pairs = fps_soap.get_keys(u_species)\n",
    "\n",
    "coefficient_subselection = np.zeros((n_FPS, 5))\n",
    "index_mapping = get_power_spectrum_index_mapping(\n",
    "    sp_pairs, n_max=hypers[\"max_radial\"], l_max=hypers[\"max_angular\"] + 1\n",
    ")\n",
    "for fi, i in enumerate(high_var_features[fps.selected_idx_]):\n",
    "    coefficient_subselection[fi] = [\n",
    "        index_mapping[i][k] for k in [\"a\", \"b\", \"n1\", \"n2\", \"l\"]\n",
    "    ]\n",
    "coefficient_subselection_dict = {\n",
    "    \"a\": coefficient_subselection[:, 0].tolist(),\n",
    "    \"b\": coefficient_subselection[:, 1].tolist(),\n",
    "    \"n1\": coefficient_subselection[:, 2].tolist(),\n",
    "    \"n2\": coefficient_subselection[:, 3].tolist(),\n",
    "    \"l\": coefficient_subselection[:, 4].tolist(),\n",
    "}\n",
    "\n",
    "soap = SOAP(**hypers, coefficient_subselection=coefficient_subselection_dict)\n",
    "idx = np.random.randint(0, len(frames), n_frames) \n",
    "my_frames= [frames[i] for i in idx]\n",
    "\n",
    "magic=magic.reshape(-1, 1)[idx]\n",
    "               \n",
    "X_raw = np.zeros((len(my_frames), n_FPS))\n",
    "for fi, frame in enumerate(my_frames):\n",
    "    X_raw[fi] = np.mean(soap.transform([frame]).get_features(soap), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_3DCD.soap.exists():\n",
    "    print('Saving the data if it doesnt already exist')\n",
    "    file=np.savez('../r4data/MP/soap.npz', idx=idx, my_frames=my_frames,\n",
    "            magic=magic ,X_raw=X_raw, coeff=coefficient_subselection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
