{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10122cc8",
   "metadata": {},
   "source": [
    "This notebook is just a demonstration on how the SOAP vectors are obtained starting from the .xyz files. \n",
    "The soap.npz files were already generated and can be downloaded, so there is no real need to run this notebook. \n",
    "If you decide to run it anyways using production data, be prepared to wait for a while, depending on the power of your RAM. The output files will be called 'generated_soap*.npz'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e78cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import DATA_3DCD, DATA_MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e359316-0110-4e6d-8a6e-cbc17780b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./modules.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10275dc7-e030-4b76-8505-9c5af77c1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_3DCD.soap.exists() and DATA_MP.soap.exists():\n",
    "    print(\"Data alreeady present, no need to execute this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_3dcd = ase.io.read(DATA_3DCD.structures, index=\":\")\n",
    "frames_mp = ase.io.read(DATA_MP.structures, index=\":\")\n",
    "len(frames_3dcd), len(frames_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = []\n",
    "for frame in tqdm(frames_3dcd):\n",
    "    for n in list(set(frame.numbers)):\n",
    "        if n not in species:\n",
    "            species.append(n)\n",
    "for frame in tqdm(frames_mp):\n",
    "    for n in list(set(frame.numbers)):\n",
    "        if n not in species:\n",
    "            species.append(n)\n",
    "len(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    \"cutoff\": 3.5,\n",
    "    \"max_angular\": 4,\n",
    "    \"max_radial\": 4,\n",
    "    \"atomic_gaussian_width\": 0.5,\n",
    "    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n",
    "    \"radial_basis\": {\"SplinedGto\": {\"accuracy\": 1e-6}},\n",
    "    \"gradients\": False,\n",
    "    'center_atom_weight': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/rca/source_installs/alchemical-learning')\n",
    "from utils.combine.alchemical import _species_coupling_matrix\n",
    "M = _species_coupling_matrix(species)\n",
    "pca = PCA()\n",
    "M_PC = pca.fit_transform(M)\n",
    "plt.semilogy(np.cumsum(pca.explained_variance_ratio_[:100]))\n",
    "N_PSEUDO = np.where(np.cumsum(pca.explained_variance_ratio_[:100])>0.99)[0][0]\n",
    "N_PSEUDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cProfile\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ase.io\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/rca/source_installs/alchemical-learning/')\n",
    "from utils.dataset import AtomisticDataset, create_dataloader\n",
    "from utils.soap import PowerSpectrum\n",
    "\n",
    "from utils.combine import CombineSpecies, CombineRadial, CombineRadialSpecies\n",
    "from utils.combine.alchemical import _species_coupling_matrix\n",
    "from utils.linear import LinearModel\n",
    "from utils.operations import SumStructures, remove_gradient\n",
    "from equistore import TensorMap, Labels, TensorBlock\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "class CombinedLinearModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        combiner,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sum_structure = SumStructures()\n",
    "        self.combiner = combiner\n",
    "        self.power_spectrum = PowerSpectrum()\n",
    "\n",
    "    def forward(self, dataloader):\n",
    "        raw_power_spectra = []\n",
    "        indices = []\n",
    "        for (spherical_expansion, _, _), idx in zip(dataloader, tqdm(dataloader.batch_sampler)):\n",
    "            combined = self.combiner(spherical_expansion)\n",
    "            power_spectrum = self.power_spectrum(combined)\n",
    "            for i, p in zip(idx, self.sum_structure(power_spectrum).block().values):\n",
    "                raw_power_spectra.append(p.detach().numpy())\n",
    "                indices.append(i)\n",
    "        return np.array(raw_power_spectra)[np.argsort(indices)].reshape((len(indices), -1)), np.array(indices)[np.argsort(indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f38935",
   "metadata": {},
   "outputs": [],
   "source": [
    "combiner = CombineSpecies(species=species, n_pseudo_species=N_PSEUDO)\n",
    "clm = CombinedLinearModel(combiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d62f2e",
   "metadata": {
    "code_folding": [
     4,
     12,
     22,
     51
    ]
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = f'power_spectrum_trial_{N_PSEUDO}-species.npz'\n",
    "ifn =  fn.replace('power_spectrum', 'indices')\n",
    "\n",
    "if not os.path.exists(fn):\n",
    "\n",
    "    if not os.path.exists(ifn):\n",
    "        n_trial = 5000\n",
    "        i_trial_3dcd = np.random.choice(len(frames_3dcd), size=n_trial//2)\n",
    "        i_trial_mp = np.random.choice(len(frames_mp), size=n_trial//2)\n",
    "\n",
    "        # removing the frames that have very close atoms\n",
    "        for i,v in enumerate(i_trial_3dcd):\n",
    "            dists = frames_3dcd[v].get_all_distances()\n",
    "            np.fill_diagonal(dists, 100.0)\n",
    "            while np.min(dists)<0.1:\n",
    "                v = np.random.choice(len(frames_3dcd))\n",
    "                if v not in i_trial_3dcd:\n",
    "                    i_trial_3dcd[i] = v\n",
    "                    dists = frames_3dcd[v].get_all_distances()\n",
    "                    np.fill_diagonal(dists, 100.0)\n",
    "\n",
    "        for i,v in enumerate(i_trial_mp):\n",
    "            dists = frames_mp[v].get_all_distances()\n",
    "            np.fill_diagonal(dists, 100.0)\n",
    "            while np.min(dists)<0.1:\n",
    "                v = np.random.choice(len(frames_mp))\n",
    "                if v not in i_trial_mp:\n",
    "                    i_trial_mp[i] = v\n",
    "                    dists = frames_mp[v].get_all_distances()\n",
    "                    np.fill_diagonal(dists, 100.0)\n",
    "        np.savez(file=ifn, i_trial_3dcd=i_trial_3dcd, i_trial_mp=i_trial_mp)\n",
    "    else:\n",
    "        d = np.load(ifn)\n",
    "        i_trial_3dcd = d['i_trial_3dcd']\n",
    "        i_trial_mp = d['i_trial_mp']\n",
    "                \n",
    "    trial_frames = np.concatenate(([frames_3dcd[i] for i in i_trial_3dcd],\n",
    "                                   [frames_mp[i] for i in i_trial_mp]))\n",
    "    print(fn)\n",
    "    temp_ds = AtomisticDataset(trial_frames, species, hypers, save_spherical_expansions=False, \n",
    "                               energies=torch.Tensor(np.zeros((len(trial_frames),1))))\n",
    "    temp_dl = create_dataloader(temp_ds, 10, shuffle=False, device='cpu')\n",
    "    ps = clm.forward(temp_dl)\n",
    "\n",
    "    np.savez(file=fn, arr=ps[0], i_trial_3dcd=i_trial_3dcd, i_trial_mp=i_trial_mp)\n",
    "    \n",
    "    x_scaler = StandardFlexibleScaler(column_wise=False).fit(ps[0])\n",
    "    x = x_scaler.transform(ps[0])\n",
    "    del ps\n",
    "    pickle.dump(x_scaler, open(f'x_scaler-{N_PSEUDO}-species.pkl', 'wb'))\n",
    "else:\n",
    "    f = np.load(fn)\n",
    "    idx = np.load(ifn)\n",
    "    for i, j in zip(idx['i_trial_mp'], f['i_trial_mp']):\n",
    "        if i != j:\n",
    "            raise AssertionError(\"Datasets do not match\")\n",
    "    for i, j in zip(idx['i_trial_3dcd'], f['i_trial_3dcd']):\n",
    "        if i != j:\n",
    "            raise AssertionError(\"Datasets do not match\")\n",
    "    x_scaler = pickle.load(open(f'x_scaler-{N_PSEUDO}-species.pkl', 'rb'))\n",
    "    x = x_scaler.transform(f['arr'])\n",
    "    i_trial_3dcd = f['i_trial_3dcd']\n",
    "    i_trial_mp = f['i_trial_mp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2000)\n",
    "pca.fit(x)\n",
    "plt.semilogy(pca.explained_variance_ratio_[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241282d0",
   "metadata": {
    "code_folding": [
     1,
     6
    ]
   },
   "outputs": [],
   "source": [
    "fn = f'pca-{N_PSEUDO}-species.pkl'\n",
    "if not os.path.exists(fn):\n",
    "    pca = PCA(n_components=2000)\n",
    "    pca.fit(x)\n",
    "    plt.semilogy(pca.explained_variance_ratio_[:2000])\n",
    "    pickle.dump(pca, open(fn, 'wb'))\n",
    "else:\n",
    "    pca = pickle.load(open(fn, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pca.transform(x)\n",
    "del x\n",
    "plt.scatter(t[:,0], t[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemiscope import show as cshow\n",
    "trial_frames = np.concatenate(([frames_3dcd[i] for i in i_trial_3dcd],\n",
    "                                   [frames_mp[i] for i in i_trial_mp]))\n",
    "source = np.zeros(len(trial_frames))\n",
    "source[:len(source)//2] = 1\n",
    "widget = cshow(frames=trial_frames, properties={\"pca\": t[:, :10], \"source\":source})\n",
    "widget.save('temp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(frames_3dcd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9142687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "fn = f'power_spectrum_pca_3dcd_{N_PSEUDO}-species.npy'\n",
    "if not os.path.exists(fn):\n",
    "    ps_pca = np.nan * np.ones((len(frames_3dcd), pca.n_components_))\n",
    "else:\n",
    "    ps_pca = np.load(fn)\n",
    "    \n",
    "pbar.reset(total=len(frames_3dcd))\n",
    "print(fn)\n",
    "for arr in np.array_split(range(len(frames_3dcd)), 100):\n",
    "    ps = None\n",
    "    temp_ds=None\n",
    "    temp_dl=None\n",
    "    frame_subset = np.array(frames_3dcd, dtype=object)[arr]\n",
    "    if np.isnan(ps_pca[arr]).any():\n",
    "        clear_output()\n",
    "        temp_ds = AtomisticDataset(frame_subset, species, hypers, save_spherical_expansions=False, \n",
    "                                   energies=torch.Tensor(np.zeros((len(frame_subset),1))))\n",
    "        temp_dl = create_dataloader(temp_ds, 10, shuffle=False, device='cpu')\n",
    "        ps = clm.forward(temp_dl)\n",
    "        ps_pca[arr] = pca.transform(x_scaler.transform(ps[0]))\n",
    "\n",
    "        np.save(file=fn, arr=ps_pca)\n",
    "    pbar.update(len(frame_subset))\n",
    "del frames_3dcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(frames_mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "fn = f'power_spectrum_pca_mp_{N_PSEUDO}-species.npy'\n",
    "if not os.path.exists(fn):\n",
    "    ps_pca = np.nan * np.ones((len(frames_mp), pca.n_components_))\n",
    "else:\n",
    "    ps_pca = np.load(fn)\n",
    "    \n",
    "print(fn)\n",
    "for arr in np.array_split(range(len(frames_mp)), 100):\n",
    "    ps = None\n",
    "    if np.isnan(ps_pca[arr]).any():\n",
    "        ps = None\n",
    "        temp_ds=None\n",
    "        temp_dl=None\n",
    "        clear_output()\n",
    "        frame_subset = np.array(frames_mp, dtype=object)[arr]\n",
    "        temp_ds = AtomisticDataset(frame_subset, species, hypers, save_spherical_expansions=False, \n",
    "                                   energies=torch.Tensor(np.zeros((len(frame_subset),1))))\n",
    "        temp_dl = create_dataloader(temp_ds, 10, shuffle=False, device='cpu')\n",
    "        ps = clm.forward(temp_dl)\n",
    "        ps_pca[arr] = pca.transform(x_scaler.transform(ps[0]))\n",
    "        pbar.update(len(frame_subset))\n",
    "\n",
    "        np.save(file=fn, arr=ps_pca)\n",
    "del frames_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93260d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
